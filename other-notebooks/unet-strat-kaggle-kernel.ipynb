{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00833d394e3069216af171fd979c814e7e1e430d",
        "_kg_hide-input": true,
        "_kg_hide-output": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport sys\nimport random\nimport warnings\nimport random as rn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage.color import rgb2gray\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input,Lambda,Conv2D, Conv2DTranspose,MaxPooling2D,concatenate,Dropout,BatchNormalization,UpSampling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.losses import binary_crossentropy\nfrom imgaug import augmenters as iaa\n\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b1753ddf3b6825401d2ed796da022dc43cab8c5c"
      },
      "cell_type": "markdown",
      "source": "## Setting up the seeds to make sure no random things happen"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "41cf465b81d140dd2e3935e54119ec7e2681ebd4"
      },
      "cell_type": "code",
      "source": "def init_seeds(seed):\n    os.environ['PYTHONHASHSEED'] = '0'\n\n    # The below is necessary for starting Numpy generated random numbers\n    # in a well-defined initial state.\n\n    np.random.seed(seed)\n\n    # The below is necessary for starting core Python generated random numbers\n    # in a well-defined state.\n\n    rn.seed(seed)\n\n    # Force TensorFlow to use single thread.\n    # Multiple threads are a potential source of\n    # non-reproducible results.\n    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n\n    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\n\n    # The below tf.set_random_seed() will make random number generation\n    # in the TensorFlow backend have a well-defined initial state.\n    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n\n    tf.set_random_seed(seed)\n\n    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n    K.set_session(sess)\n    return sess\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c",
        "_kg_hide-input": true,
        "_kg_hide-output": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Set some parameters\nn_pixels = 128\nchannels = 1\npath_train = '../input/train/'\npath_test = '../input/test/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "034cbfecacf915fdef0f19572cbf3401ee8879c8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train=pd.read_csv(\"../input/train.csv\")\nprint(train.shape)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c672d9bf3127dd10ed54e2e358887913f7ba6684",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sample=pd.read_csv(\"../input/sample_submission.csv\")\nprint(sample.shape)\nsample.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62af04fae70adc7d449fd6bc8ae7a7668941562d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "depth=pd.read_csv(\"../input/depths.csv\")\nprint(depth.shape)\ndepth.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "11da35d0fd003b90f3f37f5a07a52f0fe2fd00c9"
      },
      "cell_type": "code",
      "source": "train_ids = train.id.values\ntest_ids = sample.id.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8f02165966489c8a21bb7127bb88e7cf607599d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Get and resize train images and masks\nX = np.zeros((len(train_ids), n_pixels, n_pixels, channels), dtype=np.uint8)\ny = np.zeros((len(train_ids), n_pixels, n_pixels, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    x = np.array(load_img(path + '/images/' + id_+\".png\",grayscale=False))\n#     x = img_to_array(img)[:,:,1]\n    x=x[:,:,1]\n    x = resize(x, (n_pixels,n_pixels, channels), mode='constant', preserve_range=True)\n    X[n] = x\n    mask = np.array(load_img(path + '/masks/' + id_+\".png\",grayscale=True))\n    y[n] = resize(mask, (n_pixels,n_pixels,1), mode='constant', preserve_range=True)\n\nprint('Done!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4ecd00b0e4251e0a88761ca157f95498341e5f5f"
      },
      "cell_type": "markdown",
      "source": "## VALIDATION SPLIT AND STRATIFICATION\n\nCalculating the salt coverage class"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bda2b104818bd2a34e38a8a4656becf347b54b76",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "coverage=np.zeros((train_ids.shape[0],))\nfor i,name in tqdm_notebook(enumerate(train_ids),total=train_ids.shape[0]):\n    coverage[i]=np.sum(y[i,:,:,0])\n\ntrain['coverage']=pd.Series(coverage)/y.shape[1]**2\n\nprint(train.shape)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28b1d09674c3784267429f18f4f30b92f8f14682",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain[\"coverage_class\"] = train.coverage.apply(cov_to_class)\n\nprint(train.shape)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "177c41ca1967fe881a361f3b88bc41b49fa5ee59",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.scatter(train.coverage,train.coverage_class)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "133f6b4e96c49766aa555faf9d9a9503a85827b5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "## coverage class numpy array\ncoverage=train.coverage_class.values\nprint(coverage.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f02b012df4e8a5d8a9c9e5d733ffc9a75093e98c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def crop_rescale_image(image,mask,state,limit):\n    np.random.seed(state)\n    h,w=image.shape[0],image.shape[1]\n    dy=int(h*limit)\n    y0=np.random.randint(0,dy)\n    y1=h-y0\n    \n    np.random.seed(state+5000)\n    dx=int(w*limit)\n    x0=np.random.randint(0,dx)\n    x1=w-x0\n    \n    cropped_image=resize(image[y0:y1,x0:x1,:],(h,w),mode='constant',preserve_range=True)\n    cropped_mask=resize(mask[y0:y1,x0:x1,:],(h,w),mode='constant',preserve_range=True)\n    \n    return cropped_image,cropped_mask\n    \ndef random_crop_rescale(X,y,limit):\n    m=X.shape[0]\n    processed_image=np.zeros(X.shape)\n    processed_mask=np.zeros(y.shape)\n    for i in range(m):\n        processed_image[i,:,:,:],processed_mask[i,:,:,:]=crop_rescale_image(X[i,:,:,:],y[i,:,:,:],i,limit)\n    \n    return processed_image,processed_mask",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "a19431df18d60be92b7c18271e7d92230034ffa4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# augmentation\nprint(\"Before augmentation\",X.shape,y.shape,coverage.shape)\n# flipping in left/right \n\nX=np.append(X,[np.fliplr(x) for x in X],axis=0)\ny=np.append(y,[np.fliplr(i) for i in y],axis=0)\ncoverage=np.append(coverage,coverage,axis=0)\n\nprint(\"After Augmentation\",X.shape,y.shape,coverage.shape)\n\n\nnp.random.seed(42)\nindex=np.arange(0,4000)\n# shuffling the array\nnp.random.shuffle(index)\n\n# add gaussian blur to ranomly selected 800 images (20 %)\nseq = iaa.Sequential([\n    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n])\nX=np.append(X,seq.augment_images(X[index[0:1600]]),axis=0)\ny=np.append(y,y[0:1600],axis=0)\ncoverage=np.append(coverage,coverage[0:1600],axis=0)\n\n# doing the random crop and rescale the image.\n\nprocessed_X,processed_y=random_crop_rescale(X[index[1600:4000]],y[index[1600:4000]],limit=0.25)\nX=np.append(X,processed_X,axis=0)\ny=np.append(y,processed_y,axis=0)\ncoverage=np.append(coverage,coverage[index[1600:4000]],axis=0)\n\nprint(\"After Augmentation\",X.shape,y.shape,coverage.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "783dc7661f9f3f6218ff30515c026a6bca33d589"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7146b107c8364631b29b1efaa54f5fd0271c9b29",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# split\n\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,stratify=coverage,random_state=42)\n\n\nprint(X_train.shape,X_val.shape)\nprint(y_train.shape,y_val.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d66a11a8d8d48e16640307185062f5494c1f5b6"
      },
      "cell_type": "markdown",
      "source": "# Train Model\nMetrics copied from public kernels"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b4716a2112dfb71c75e60bff90cb17836f78bf66"
      },
      "cell_type": "code",
      "source": "## metric,copied from https://www.kaggle.com/jcesquiveld/tgs-simple-u-net-baseline\n\ndef castF(x):\n    return K.cast(x, K.floatx())\n\ndef castB(x):\n    return K.cast(x, bool)\n\ndef iou_loss_core(true,pred):\n    intersection = true * pred\n    notTrue = 1 - true\n    union = true + (notTrue * pred)\n\n    return (K.sum(intersection, axis=-1) + K.epsilon()) / (K.sum(union, axis=-1) + K.epsilon())\n\ndef competition_metric(true, pred): #any shape can go\n\n    tresholds = [0.5 + (i*.05)  for i in range(10)]\n\n    #flattened images (batch, pixels)\n    true = K.batch_flatten(true)\n    pred = K.batch_flatten(pred)\n    pred = castF(K.greater(pred, 0.5))\n\n    #total white pixels - (batch,)\n    trueSum = K.sum(true, axis=-1)\n    predSum = K.sum(pred, axis=-1)\n\n    #has mask or not per image - (batch,)\n    true1 = castF(K.greater(trueSum, 1))    \n    pred1 = castF(K.greater(predSum, 1))\n\n    #to get images that have mask in both true and pred\n    truePositiveMask = castB(true1 * pred1)\n\n    #separating only the possible true positives to check iou\n    testTrue = tf.boolean_mask(true, truePositiveMask)\n    testPred = tf.boolean_mask(pred, truePositiveMask)\n\n    #getting iou and threshold comparisons\n    iou = iou_loss_core(testTrue,testPred) \n    truePositives = [castF(K.greater(iou, tres)) for tres in tresholds]\n\n    #mean of thressholds for true positives and total sum\n    truePositives = K.mean(K.stack(truePositives, axis=-1), axis=-1)\n    truePositives = K.sum(truePositives)\n\n    #to get images that don't have mask in both true and pred\n    trueNegatives = (1-true1) * (1 - pred1) # = 1 -true1 - pred1 + true1*pred1\n    trueNegatives = K.sum(trueNegatives) \n\n    return (truePositives + trueNegatives) / castF(K.shape(true)[0])\n\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2c5c2ba23becc85155a45e34af9e97b9c226b9c0"
      },
      "cell_type": "code",
      "source": "# loss\n# here i will add dice and bce loss\n# taken from https://www.kaggle.com/kmader/u-net-with-dice-and-augmentation\n\ndef dice_loss(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    score=K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n    return 1.0-score\n\ndef dice_and_bce(in_gt, in_pred):\n    \"\"\"combine DICE and BCE\"\"\"\n    return binary_crossentropy(in_gt, in_pred) + dice_loss(in_gt, in_pred)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7eaaa7846d0509faff243969f0372899d3399abc"
      },
      "cell_type": "markdown",
      "source": "## ARCHITECUTE"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58e87797db5bb02b8f0ad6a0af6592e94f9f8b3f",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "inputs = Input((n_pixels,n_pixels,channels))\n\nnormalize=True\nbatch_normalize=True\n\nif normalize:\n    s=Lambda(lambda x: x / 255) (inputs)\nelse:\n    s = inputs\n\n\n\n\n# 128 to 64\nc1 = Conv2D(16, (3, 3), activation='relu', padding='same') (s)\nc1=BatchNormalization()(c1) if batch_normalize else c1\nc1 = Conv2D(16, (3, 3), activation='relu', padding='same') (c1)\nc1=BatchNormalization()(c1) if batch_normalize else c1\np1 = MaxPooling2D((2, 2)) (c1)\n\n# 64 to 32\nc2 = Conv2D(32, (3, 3), activation='relu', padding='same') (p1)\nc2=BatchNormalization()(c2) if batch_normalize else c2\nc2 = Conv2D(32, (3, 3), activation='relu', padding='same') (c2)\nc2=BatchNormalization()(c2) if batch_normalize else c2\np2 = MaxPooling2D((2, 2)) (c2)\n\n# 32 to 16\nc3 = Conv2D(64, (3, 3), activation='relu', padding='same') (p2)\nc3=BatchNormalization()(c3) if batch_normalize else c3\nc3 = Conv2D(64, (3, 3), activation='relu', padding='same') (c3)\nc3=BatchNormalization()(c3) if batch_normalize else c3\np3 = MaxPooling2D((2, 2)) (c3)\n\n# 16 to 8\nc4 = Conv2D(128, (3, 3), activation='relu', padding='same') (p3)\nc4=BatchNormalization()(c4) if batch_normalize else c4\nc4 = Conv2D(128, (3, 3), activation='relu', padding='same') (c4)\nc4=BatchNormalization()(c4) if batch_normalize else c4\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n# middle layer\nc5 = Conv2D(256, (3, 3), activation='relu', padding='same') (p4)\nc5=BatchNormalization()(c5) if batch_normalize else c5\nc5 = Conv2D(256, (3, 3), activation='relu', padding='same') (c5)\nc5=BatchNormalization()(c5) if batch_normalize else c5\n\n# 8 to 16\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='relu', padding='same') (u6)\nc6=BatchNormalization()(c6) if batch_normalize else c6\nc6 = Conv2D(128, (3, 3), activation='relu', padding='same') (c6)\nc6=BatchNormalization()(c6) if batch_normalize else c6\n\n# 16 to 32\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='relu', padding='same') (u7)\nc7=BatchNormalization()(c7) if batch_normalize else c7\nc7 = Conv2D(64, (3, 3), activation='relu', padding='same') (c7)\nc7=BatchNormalization()(c7) if batch_normalize else c7\n\n# 32 to 64\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='relu', padding='same') (u8)\nc8=BatchNormalization()(c8) if batch_normalize else c8\nc8 = Conv2D(32, (3, 3), activation='relu', padding='same') (c8)\nc8=BatchNormalization()(c8) if batch_normalize else c8\n\n# 64 to 128\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='relu', padding='same') (u9)\nc9=BatchNormalization()(c9) if batch_normalize else c9\nc9 = Conv2D(16, (3, 3), activation='relu', padding='same') (c9)\nc9=BatchNormalization()(c9) if batch_normalize else c9\n\n# 1x1 convolution\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss=dice_and_bce, metrics=[mean_iou,competition_metric])\nmodel.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "cc6c39e944193242e011e843c75840ebb1362beb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9b8702cb1463886a4cab6dda11385f57eef7ed31"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58969e2e3bdca3b94da4ebd4e513a83455adf00a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "batch=32\nep=30\n\n## copied from https://github.com/jfpuget/LibFM_in_Keras/blob/master/keras_blog.ipynb\n# if we do this we cant use mean_iou as the metric due to initializations errors\n# try:\n#     del sess\n# except:\n#     pass\n# sess = init_seeds(0)\n\n\nname_model='stratification_unet.h5'\n\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint(name_model, verbose=1, save_best_only=True)\nreduce_lr=ReduceLROnPlateau(patience=3, min_lr=0.00001, verbose=1)\n\nresults = model.fit(X_train, y_train, validation_data=[X_val,y_val], batch_size=batch, epochs=ep, \n                    callbacks=[earlystopper, checkpointer,reduce_lr])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ab8516fb8ab135872dd4f4b895b5d76206df1fa"
      },
      "cell_type": "markdown",
      "source": "# Test Data\nFirst we'll get the test data. This takes a while, it's 18000 samples."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6d376a5ed9fa0ff708299f55a0a8ed8b8471137",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Get and resize test images\nX_test = np.zeros((len(test_ids),n_pixels,n_pixels,channels), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    img = load_img(path + '/images/' + id_+\".png\")\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce6c70505c2569807a6c84033708b314830ecd28",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = load_model(name_model, custom_objects={'competition_metric': competition_metric,'mean_iou':mean_iou,\n                                               'dice_and_bce':dice_and_bce})\nprint(model.metrics_names)\nprint(model.evaluate(X_train,y_train))\nprint(model.evaluate(X_val,y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2316034edcb7227673fd9b69264ca9c0d0e87f14",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Predict on train, val and test\npreds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_val, verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af64790cdb7e5beb05fc34635cdf092124d7dc20",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "844cded40edc71652bc5b26852245e37f46f6448"
      },
      "cell_type": "markdown",
      "source": "# Prepare Submission\nWe need to prepare the submission. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73336f76166028ba39c8164083c9564a0d5afe40",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6eaf7acaf4a0678638c5e40732c6533816777637",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7053aeadabcc4e29e1e7d9d60c920a2cc5746018",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a28699ff3b0cfe18fc9f9fb6fc3d20374988583",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub.loc[sub['rle_mask']==\"\"].shape",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}